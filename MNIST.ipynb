{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MNIST Neural Network Tutorial\n",
    "Today we are going to look into neural networks! What do we need? First we need a lot of labeled data. In this example we will use a very popular introductary dataset, the MNIST dataset. MNIST consists of images (28x28 pixels) with hand-drawn numbers ranging from 0 to 9, and their corresponding 'correct' number. \n",
    "\n",
    "For this type of data, 2D convolutional neural networks (CNN) are most appropriate. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np     \n",
    "import os                             \n",
    "import sys                 \n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist # load the MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 # NN generally performs best with inputs ranging from [0 1]\n",
    "\n",
    "print(x_train.shape)    # training data sample\n",
    "print(x_test.shape)     # testing data sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build a Neural Network!\n",
    "Cool, the data is loaded! Now let's first build a very simple network before looking into CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built a simple model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),  # input layer: transform inputs to 1D (None, 28*28=784)\n",
    "  tf.keras.layers.Dense(64, activation='relu'),   # hidden layer\n",
    "  tf.keras.layers.Dense(64, activation='relu'),   # hidden layer\n",
    "  tf.keras.layers.Dense(64, activation='relu'),   # hidden layer\n",
    "  tf.keras.layers.Dense(10, activation='softmax') # output layer\n",
    "])\n",
    "model.summary\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    batch_size=10,\n",
    "    epochs=2,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Network is trained!\n",
    "That is already a pretty large accuracy for such a simple network! Maybe we don't need any thing complicated at all? First, lets look at some of the mistakes the network makes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test)\n",
    "n = 0\n",
    "for i in range(0,len(y_test)):\n",
    "    max_index = np.argmax(prediction[i], axis=0)\n",
    "    if max_index != y_test[i]:\n",
    "        n = n + 1\n",
    "        if n < 9:\n",
    "            print(\"Network thinks it is a: \", max_index, \" but it is actually a: \", y_test[i])\n",
    "            plt.imshow(x_test[i])\n",
    "            plt.show()\n",
    "acc = (len(y_test)-n)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we do better??\n",
    "Lets try Convolutional Neural Networks! These networks can capture spatial features from images, instead of simply taking each pixel as a separte value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)), # input layer\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), # hidden layer\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),                                           # pooling layer (dimension reduction)\n",
    "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)), # hidden layer\n",
    "  tf.keras.layers.Flatten(),                                                      # transform inputs to 1D \n",
    "  tf.keras.layers.Dense(64, activation='relu'),                                   # hidden layer\n",
    "  tf.keras.layers.Dense(10, activation='softmax')                                 # Output layer\n",
    "])\n",
    "\n",
    "model_CNN.summary\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model_CNN.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model_CNN.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_CNN.predict(x_test)\n",
    "n = 0\n",
    "for i in range(0,len(y_test)):\n",
    "    max_index = np.argmax(prediction[i], axis=0)\n",
    "    if max_index != y_test[i]:\n",
    "        n = n + 1\n",
    "        if n < 9:\n",
    "            print(\"Network thinks it is a: \", max_index, \" but it is actually a: \", y_test[i])\n",
    "            plt.imshow(x_test[i])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens with new independent data?\n",
    "I made my own dataset, lets see what happens! This is a relative small dataset, with a total of 64 images, 32 with zeros and 32 with ones. What will happen when we feed this data to the network? Note that 'random guessing' would result in an accuray of 0.10 (not 0.50!), since the network expects the data to range from 0 to 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the independent test-set\n",
    "data_dir = os.path.join(sys.path[0], \"test_set\")\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*.png'))) \n",
    "images = list(data_dir.glob('*.png')) # Extract all png files\n",
    "\n",
    "y_test_gsd = [None]*image_count\n",
    "x_test_gsd = np.empty([1,28,28]) # Initialize\n",
    "\n",
    "for i in range(0,image_count):\n",
    "    if \"one\" in str(images[i]): # if filename starts with 'one' it is 1\n",
    "        y_test_gsd[i] = 1\n",
    "    else:                       # else it is a 0\n",
    "        y_test_gsd[i] = 0\n",
    "    im = imageio.imread(images[i])\n",
    "    \n",
    "    im = (255-im) /255\n",
    "    if i == 0:     # if first iter, x_test_gsd = first image\n",
    "        x_test_gsd = im[None,...]\n",
    "    else:          # else appand image to x_test_gsd\n",
    "        x_test_gsd = np.concatenate([x_test_gsd,im[None,...]],axis=0)\n",
    "\n",
    "y_test_gsd = np.array(y_test_gsd)\n",
    "\n",
    "print(x_test_gsd.shape)    # training data sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: The simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_gsd = x_test_gsd.reshape(x_test_gsd.shape[0], 28, 28, 1)\n",
    "\n",
    "prediction = model.predict(x_test_gsd)\n",
    "\n",
    "n = 0\n",
    "for i in range(0,len(y_test_gsd)):\n",
    "    max_index = np.argmax(prediction[i], axis=0)\n",
    "    if max_index != y_test_gsd[i]:\n",
    "        n = n + 1\n",
    "        if n < 9:\n",
    "            print(\"Network thinks it is a: \", max_index, \" but it is actually a: \", y_test_gsd[i])\n",
    "            plt.imshow(x_test_gsd[i])\n",
    "            plt.show()\n",
    "acc = (len(y_test_gsd)-n)/len(y_test_gsd)\n",
    "print(\"accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_gsd = x_test_gsd.reshape(x_test_gsd.shape[0], 28, 28, 1)\n",
    "\n",
    "prediction = model_CNN.predict(x_test_gsd)\n",
    "\n",
    "n = 0\n",
    "for i in range(0,len(y_test_gsd)):\n",
    "    max_index = np.argmax(prediction[i], axis=0)\n",
    "    if max_index != y_test_gsd[i]:\n",
    "        n = n + 1\n",
    "        if n < 9:\n",
    "            print(\"Network thinks it is a: \", max_index, \" but it is actually a: \", y_test_gsd[i])\n",
    "            plt.imshow(x_test_gsd[i])\n",
    "            plt.show()\n",
    "acc = (len(y_test_gsd)-n)/len(y_test_gsd)\n",
    "print(\"accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take home message\n",
    "Without an independent validation dataset the evaluation of Neural Network performance can be biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
